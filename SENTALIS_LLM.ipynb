{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ SENTALIS ‚Äî Sentiment Analysis\n",
    "## LLM Edition (seed-2-0-mini via SumoPod AI)\n",
    "\n",
    "**Input:** Dataset berlabel (`dataset_ml.csv`)  \n",
    "**Output:** Hasil prediksi sentimen menggunakan LLM + laporan evaluasi lengkap\n",
    "\n",
    "---\n",
    "\n",
    "### üó∫Ô∏è Alur Notebook\n",
    "```\n",
    "1. Load & eksplorasi dataset\n",
    "2. Analisis distribusi kelas\n",
    "3. Prediksi sentimen via LLM (zero-shot / few-shot)\n",
    "4. Evaluasi model ‚Äî accuracy, precision, recall, F1\n",
    "5. Confusion matrix & visualisasi\n",
    "6. Analisis kesalahan prediksi\n",
    "7. Prediksi teks baru interaktif\n",
    "8. Simpan hasil\n",
    "```\n",
    "\n",
    "> üìÅ Pastikan file `dataset_ml.csv` tersedia di direktori yang sama.  \n",
    "> üîë API Key SumoPod AI sudah dikonfigurasi di Cell 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Cell 1 ‚Äî Install & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pandas matplotlib seaborn tqdm -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Scikit-learn: evaluasi\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score, precision_score, recall_score\n",
    ")\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "WARNA = {'Negatif': '#FF3B30', 'Netral': '#8E8E93', 'Positif': '#34C759'}\n",
    "LABEL_ORDER = ['Negatif', 'Netral', 'Positif']\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Inisialisasi OpenAI Client dengan SumoPod AI ‚îÄ‚îÄ‚îÄ\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-vAAu3GrFUtzmkbPe5tAHSg\",\n",
    "    base_url=\"https://ai.sumopod.com/v1\"\n",
    ")\n",
    "\n",
    "MODEL_LLM = \"seed-2-0-mini-free\"\n",
    "\n",
    "print('‚úÖ Semua library berhasil diimport!')\n",
    "print(f'ü§ñ Model LLM: {MODEL_LLM}')\n",
    "\n",
    "# Uji koneksi API\n",
    "test_resp = client.chat.completions.create(\n",
    "    model=MODEL_LLM,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Balas hanya dengan kata: OK\"}],\n",
    "    max_tokens=10,\n",
    "    temperature=0\n",
    ")\n",
    "print(f'‚úÖ Koneksi API berhasil: {test_resp.choices[0].message.content.strip()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Cell 2 ‚Äî Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "USE_PRESPLIT = os.path.exists('dataset_train.csv') and os.path.exists('dataset_test.csv')\n",
    "\n",
    "if USE_PRESPLIT:\n",
    "    df_train_raw = pd.read_csv('dataset_train.csv', encoding='utf-8-sig')\n",
    "    df_test_raw  = pd.read_csv('dataset_test.csv',  encoding='utf-8-sig')\n",
    "    print(f'‚úÖ Menggunakan pre-split dataset')\n",
    "    print(f'   Train: {len(df_train_raw)} | Test: {len(df_test_raw)}')\n",
    "else:\n",
    "    for enc in ['utf-8-sig', 'utf-8', 'latin-1']:\n",
    "        try:\n",
    "            df_full = pd.read_csv('dataset_ml.csv', encoding=enc)\n",
    "            print(f'‚úÖ Loaded dataset_ml.csv ({enc})')\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "def normalize_df(df):\n",
    "    df = df.copy()\n",
    "    df['teks_bersih'] = df['teks_bersih'].fillna('').astype(str).str.strip()\n",
    "    df = df[df['teks_bersih'].str.len() > 0].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "if USE_PRESPLIT:\n",
    "    df_train_raw = normalize_df(df_train_raw)\n",
    "    df_test_raw  = normalize_df(df_test_raw)\n",
    "    df_full = pd.concat([df_train_raw, df_test_raw], ignore_index=True)\n",
    "else:\n",
    "    df_full = normalize_df(df_full)\n",
    "\n",
    "print(f'\\nüìä Total data: {len(df_full)}')\n",
    "print(f'üìã Kolom    : {list(df_full.columns)}')\n",
    "display(df_full[['teks_bersih', 'label']].head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Cell 3 ‚Äî Eksplorasi & Analisis Distribusi Kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = df_full['label'].value_counts()\n",
    "total = len(df_full)\n",
    "\n",
    "print('=' * 50)\n",
    "print('üìä DISTRIBUSI KELAS')\n",
    "print('=' * 50)\n",
    "for label in LABEL_ORDER:\n",
    "    n = dist.get(label, 0)\n",
    "    pct = n / total * 100\n",
    "    bar = '‚ñà' * int(pct / 2.5)\n",
    "    print(f'  {label:10s} {bar:30s} {n:4d} ({pct:.1f}%)')\n",
    "print(f'  Total     {\" \" * 30} {total}')\n",
    "\n",
    "n_max = dist.max()\n",
    "n_min = dist.min()\n",
    "ratio = n_max / n_min\n",
    "print(f'\\n‚ö†Ô∏è  Imbalance Ratio: {ratio:.1f}x')\n",
    "\n",
    "if ratio > 5:\n",
    "    print('\\n‚ùó Dataset SANGAT TIDAK SEIMBANG.')\n",
    "    print('   Catatan: LLM zero-shot tidak terpengaruh class imbalance secara langsung.')\n",
    "elif ratio > 2:\n",
    "    print('\\n‚ö° Dataset cukup tidak seimbang.')\n",
    "else:\n",
    "    print('\\n‚úÖ Dataset cukup seimbang.')\n",
    "\n",
    "df_full['n_kata'] = df_full['teks_bersih'].str.split().str.len()\n",
    "print('\\n‚îÄ‚îÄ‚îÄ Rata-rata panjang teks per kelas ‚îÄ‚îÄ‚îÄ')\n",
    "for label in LABEL_ORDER:\n",
    "    sub = df_full[df_full['label'] == label]['n_kata']\n",
    "    if len(sub) > 0:\n",
    "        print(f'  {label:10s}: rata {sub.mean():.1f} kata, max {sub.max()} kata')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "fig.patch.set_facecolor('#F2F2F7')\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_facecolor('white')\n",
    "bars = ax.bar(LABEL_ORDER,\n",
    "              [dist.get(l, 0) for l in LABEL_ORDER],\n",
    "              color=[WARNA[l] for l in LABEL_ORDER],\n",
    "              edgecolor='white', width=0.55)\n",
    "for bar, label in zip(bars, LABEL_ORDER):\n",
    "    h = bar.get_height()\n",
    "    pct = h / total * 100\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, h + 2,\n",
    "            f'{int(h)}\\n({pct:.1f}%)', ha='center', fontsize=10, fontweight='bold')\n",
    "ax.set_title('Distribusi Kelas', fontweight='bold', fontsize=13)\n",
    "ax.set_ylabel('Jumlah Sampel')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.set_facecolor('white')\n",
    "data_box = [df_full[df_full['label'] == l]['n_kata'].values for l in LABEL_ORDER]\n",
    "bp = ax2.boxplot(data_box, patch_artist=True, labels=LABEL_ORDER,\n",
    "                 medianprops=dict(color='white', linewidth=2))\n",
    "for patch, label in zip(bp['boxes'], LABEL_ORDER):\n",
    "    patch.set_facecolor(WARNA[label])\n",
    "    patch.set_alpha(0.8)\n",
    "ax2.set_title('Sebaran Panjang Teks (kata)', fontweight='bold', fontsize=13)\n",
    "ax2.set_ylabel('Jumlah Kata')\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout(pad=2)\n",
    "plt.savefig('llm_distribusi_kelas.png', dpi=150, bbox_inches='tight', facecolor='#F2F2F7')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Cell 4 ‚Äî Train / Test Split\n",
    "\n",
    "> Untuk LLM zero-shot, kita **tidak perlu** data training.  \n",
    "> Namun tetap melakukan split agar evaluasi konsisten dengan baseline ML.  \n",
    "> Beberapa contoh dari data train digunakan sebagai **few-shot examples** dalam prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_full['teks_bersih'].values\n",
    "y = df_full['label'].values\n",
    "\n",
    "if USE_PRESPLIT:\n",
    "    X_train = df_train_raw['teks_bersih'].values\n",
    "    y_train = df_train_raw['label'].values\n",
    "    X_test  = df_test_raw['teks_bersih'].values\n",
    "    y_test  = df_test_raw['label'].values\n",
    "    print('‚úÖ Menggunakan pre-split (dari file train/test terpisah)')\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print('‚úÖ Stratified split 80/20 selesai')\n",
    "\n",
    "print(f'\\n   Train : {len(X_train)} sampel (digunakan sebagai few-shot pool)')\n",
    "print(f'   Test  : {len(X_test)} sampel (dievaluasi oleh LLM)')\n",
    "\n",
    "# Ambil few-shot examples: 2 per kelas dari data train\n",
    "FEW_SHOT_N = 2\n",
    "few_shot_examples = []\n",
    "for label in LABEL_ORDER:\n",
    "    idx = np.where(y_train == label)[0]\n",
    "    # Pilih contoh dengan panjang sedang (tidak terlalu pendek/panjang)\n",
    "    lengths = np.array([len(X_train[i].split()) for i in idx])\n",
    "    med = np.median(lengths)\n",
    "    sorted_idx = idx[np.argsort(np.abs(lengths - med))]\n",
    "    for i in sorted_idx[:FEW_SHOT_N]:\n",
    "        few_shot_examples.append({'teks': X_train[i], 'label': label})\n",
    "\n",
    "print(f'\\nüìö Few-shot examples ({FEW_SHOT_N} per kelas):')\n",
    "for ex in few_shot_examples:\n",
    "    icon = {'Negatif': 'üî¥', 'Netral': '‚ö™', 'Positif': 'üü¢'}[ex['label']]\n",
    "    print(f'   {icon} [{ex[\"label\"]}] \"{ex[\"teks\"][:60]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Cell 5 ‚Äî Desain Prompt & Fungsi Prediksi LLM\n",
    "\n",
    "Kita gunakan pendekatan **few-shot prompting** agar LLM lebih memahami konteks dataset  \n",
    "(komentar warga tentang pemerintah/infrastruktur daerah dalam Bahasa Indonesia/Sunda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ Buat System Prompt ‚îÄ‚îÄ‚îÄ\n",
    "SYSTEM_PROMPT = \"\"\"Kamu adalah sistem analisis sentimen untuk komentar warga mengenai layanan pemerintah daerah, infrastruktur, dan kebijakan publik dalam Bahasa Indonesia dan Bahasa Sunda.\n",
    "\n",
    "Tugasmu adalah mengklasifikasikan sentimen komentar menjadi salah satu dari tiga kategori:\n",
    "- Negatif: komentar yang mengungkapkan ketidakpuasan, keluhan, kritik, atau kekecewaan\n",
    "- Netral: komentar yang bersifat informatif, pertanyaan, atau tidak jelas arah sentimennya\n",
    "- Positif: komentar yang mengungkapkan kepuasan, apresiasi, pujian, atau dukungan\n",
    "\n",
    "Aturan:\n",
    "1. Jawab HANYA dengan satu kata: Negatif, Netral, atau Positif\n",
    "2. Jangan tambahkan penjelasan, tanda baca, atau kata lain apapun\n",
    "3. Perhatikan konteks lokal dan ungkapan dalam Bahasa Sunda\"\"\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Buat Few-Shot Messages ‚îÄ‚îÄ‚îÄ\n",
    "def build_few_shot_messages(examples):\n",
    "    \"\"\"Buat daftar few-shot message dari contoh berlabel.\"\"\"\n",
    "    messages = []\n",
    "    for ex in examples:\n",
    "        messages.append({\"role\": \"user\", \"content\": ex['teks']})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": ex['label']})\n",
    "    return messages\n",
    "\n",
    "FEW_SHOT_MESSAGES = build_few_shot_messages(few_shot_examples)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Fungsi Prediksi LLM ‚îÄ‚îÄ‚îÄ\n",
    "def predict_llm(teks, max_retries=3, delay=1.0):\n",
    "    \"\"\"\n",
    "    Prediksi sentimen satu teks menggunakan LLM.\n",
    "    Returns: label string ('Negatif', 'Netral', 'Positif') atau None jika gagal\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        *FEW_SHOT_MESSAGES,\n",
    "        {\"role\": \"user\", \"content\": str(teks).strip()}\n",
    "    ]\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL_LLM,\n",
    "                messages=messages,\n",
    "                max_tokens=10,\n",
    "                temperature=0  # deterministic\n",
    "            )\n",
    "            raw = response.choices[0].message.content.strip()\n",
    "\n",
    "            # Normalisasi output\n",
    "            raw_lower = raw.lower()\n",
    "            if 'negatif' in raw_lower or 'negative' in raw_lower:\n",
    "                return 'Negatif'\n",
    "            elif 'positif' in raw_lower or 'positive' in raw_lower:\n",
    "                return 'Positif'\n",
    "            elif 'netral' in raw_lower or 'neutral' in raw_lower:\n",
    "                return 'Netral'\n",
    "            else:\n",
    "                # Fallback: cek apakah persis salah satu label\n",
    "                for label in LABEL_ORDER:\n",
    "                    if raw.strip() == label:\n",
    "                        return label\n",
    "                # Jika tidak dikenali, default Netral\n",
    "                print(f'  ‚ö†Ô∏è  Output tidak dikenali: \"{raw}\" ‚Üí default Netral')\n",
    "                return 'Netral'\n",
    "\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f'  ‚ö†Ô∏è  Retry {attempt+1}/{max_retries}: {e}')\n",
    "                time.sleep(delay * (attempt + 1))\n",
    "            else:\n",
    "                print(f'  ‚ùå Gagal setelah {max_retries} percobaan: {e}')\n",
    "                return None\n",
    "\n",
    "# Test fungsi prediksi\n",
    "print('üß™ Test prediksi LLM:')\n",
    "contoh_test = [\n",
    "    ('Jalanan rusak parah, sudah bertahun-tahun tidak diperbaiki!', 'Negatif'),\n",
    "    ('Terima kasih pak bupati, programnya sangat membantu warga.', 'Positif'),\n",
    "    ('Kapan pendaftaran bantuan sosial dibuka?', 'Netral'),\n",
    "]\n",
    "for teks, expected in contoh_test:\n",
    "    pred = predict_llm(teks)\n",
    "    icon_pred = {'Negatif': 'üî¥', 'Netral': '‚ö™', 'Positif': 'üü¢'}.get(pred, '‚ö´')\n",
    "    icon_exp  = {'Negatif': 'üî¥', 'Netral': '‚ö™', 'Positif': 'üü¢'}.get(expected, '‚ö´')\n",
    "    status = '‚úÖ' if pred == expected else '‚ùå'\n",
    "    print(f'  {status} Pred: {icon_pred} {pred:8s} | Expected: {icon_exp} {expected:8s} | \"{teks[:55]}\"')\n",
    "\n",
    "print(f'\\n‚úÖ Fungsi prediksi LLM siap digunakan!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Cell 6 ‚Äî Jalankan Prediksi pada Test Set\n",
    "\n",
    "> ‚ö†Ô∏è **Perhatian:** Cell ini akan memanggil API sebanyak `len(X_test)` kali.  \n",
    "> Untuk dataset besar, pertimbangkan untuk menetapkan `MAX_SAMPLES` agar lebih cepat.  \n",
    "> Set `MAX_SAMPLES = None` untuk memproses semua data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ Konfigurasi ‚îÄ‚îÄ‚îÄ\n",
    "MAX_SAMPLES = 200   # Set None untuk semua data, atau integer untuk subset\n",
    "DELAY_BETWEEN_CALLS = 0.3  # detik antar API call (hindari rate limit)\n",
    "\n",
    "if MAX_SAMPLES is not None and MAX_SAMPLES < len(X_test):\n",
    "    # Stratified sampling agar distribusi label terjaga\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    idx_sample = []\n",
    "    for label in LABEL_ORDER:\n",
    "        idx_label = np.where(y_test == label)[0]\n",
    "        n_take = max(1, int(MAX_SAMPLES * len(idx_label) / len(y_test)))\n",
    "        idx_sample.extend(np.random.choice(idx_label, min(n_take, len(idx_label)), replace=False))\n",
    "    idx_sample = sorted(idx_sample)\n",
    "    X_eval = X_test[idx_sample]\n",
    "    y_eval = y_test[idx_sample]\n",
    "    print(f'üìã Evaluasi subset: {len(X_eval)} sampel dari {len(X_test)} total')\n",
    "else:\n",
    "    X_eval = X_test\n",
    "    y_eval = y_test\n",
    "    print(f'üìã Evaluasi semua test data: {len(X_eval)} sampel')\n",
    "\n",
    "print(f'\\nüöÄ Mulai prediksi LLM...')\n",
    "print(f'   Estimasi waktu: ~{len(X_eval) * DELAY_BETWEEN_CALLS / 60:.1f} menit')\n",
    "print()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Loop Prediksi ‚îÄ‚îÄ‚îÄ\n",
    "y_pred_llm = []\n",
    "failed_idx = []\n",
    "\n",
    "for i, teks in enumerate(tqdm(X_eval, desc='Prediksi LLM')):\n",
    "    pred = predict_llm(teks)\n",
    "    if pred is None:\n",
    "        pred = 'Netral'  # default jika gagal\n",
    "        failed_idx.append(i)\n",
    "    y_pred_llm.append(pred)\n",
    "    if DELAY_BETWEEN_CALLS > 0:\n",
    "        time.sleep(DELAY_BETWEEN_CALLS)\n",
    "\n",
    "y_pred_llm = np.array(y_pred_llm)\n",
    "\n",
    "print(f'\\n‚úÖ Prediksi selesai!')\n",
    "print(f'   Total: {len(y_pred_llm)}')\n",
    "print(f'   Gagal/fallback: {len(failed_idx)}')\n",
    "\n",
    "# Simpan hasil sementara\n",
    "df_hasil = pd.DataFrame({\n",
    "    'teks': X_eval,\n",
    "    'label_aktual': y_eval,\n",
    "    'pred_llm': y_pred_llm,\n",
    "})\n",
    "df_hasil['benar'] = df_hasil['label_aktual'] == df_hasil['pred_llm']\n",
    "\n",
    "print(f'\\nüìà Quick result:')\n",
    "acc_quick = accuracy_score(y_eval, y_pred_llm)\n",
    "f1_quick  = f1_score(y_eval, y_pred_llm, average='macro', zero_division=0)\n",
    "print(f'   Accuracy : {acc_quick:.4f}')\n",
    "print(f'   Macro F1 : {f1_quick:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Cell 7 ‚Äî Evaluasi Detail & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('üìä CLASSIFICATION REPORT ‚Äî LLM (seed-2-0-mini)')\n",
    "print('=' * 60)\n",
    "print(classification_report(y_eval, y_pred_llm, target_names=LABEL_ORDER, zero_division=0))\n",
    "\n",
    "precision = precision_score(y_eval, y_pred_llm, labels=LABEL_ORDER, average=None, zero_division=0)\n",
    "recall    = recall_score(y_eval, y_pred_llm, labels=LABEL_ORDER, average=None, zero_division=0)\n",
    "f1        = f1_score(y_eval, y_pred_llm, labels=LABEL_ORDER, average=None, zero_division=0)\n",
    "support   = [np.sum(y_eval == l) for l in LABEL_ORDER]\n",
    "\n",
    "df_report = pd.DataFrame({\n",
    "    'Kelas':     LABEL_ORDER,\n",
    "    'Precision': [f'{p:.3f}' for p in precision],\n",
    "    'Recall':    [f'{r:.3f}' for r in recall],\n",
    "    'F1-Score':  [f'{f:.3f}' for f in f1],\n",
    "    'Support':   support,\n",
    "})\n",
    "\n",
    "macro_f1 = f1_score(y_eval, y_pred_llm, average='macro', zero_division=0)\n",
    "acc      = accuracy_score(y_eval, y_pred_llm)\n",
    "\n",
    "print(f'\\nüìà Ringkasan:')\n",
    "print(f'   Accuracy       : {acc:.4f} ({acc*100:.2f}%)')\n",
    "print(f'   Macro F1       : {macro_f1:.4f}')\n",
    "print(f'   Weighted F1    : {f1_score(y_eval, y_pred_llm, average=\"weighted\", zero_division=0):.4f}')\n",
    "print()\n",
    "display(df_report)\n",
    "\n",
    "# Visualisasi metrik per kelas\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "fig.patch.set_facecolor('#F2F2F7')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "x = np.arange(len(LABEL_ORDER))\n",
    "w = 0.25\n",
    "metrics_vals = [precision, recall, f1]\n",
    "metric_names = ['Precision', 'Recall', 'F1-Score']\n",
    "m_colors     = ['#007AFF', '#5856D6', '#34C759']\n",
    "\n",
    "for i, (vals, name, color) in enumerate(zip(metrics_vals, metric_names, m_colors)):\n",
    "    bars = ax.bar(x + i * w, vals, w, label=name, color=color, alpha=0.85, edgecolor='white')\n",
    "    for bar, val in zip(bars, vals):\n",
    "        if val > 0:\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,\n",
    "                    f'{val:.2f}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "ax.set_xticks(x + w)\n",
    "ax.set_xticklabels(LABEL_ORDER, fontsize=11)\n",
    "ax.set_ylim(0, 1.15)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Precision / Recall / F1 per Kelas ‚Äî LLM (seed-2-0-mini)',\n",
    "             fontweight='bold', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.axhline(y=macro_f1, color='gray', linestyle='--', linewidth=1, alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('llm_metrik_kelas.png', dpi=150, bbox_inches='tight', facecolor='#F2F2F7')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üü¶ Cell 8 ‚Äî Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "fig.patch.set_facecolor('#F2F2F7')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "cm = confusion_matrix(y_eval, y_pred_llm, labels=LABEL_ORDER)\n",
    "cm_pct = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "annot = np.array(\n",
    "    [[f'{cm[i,j]}\\n({cm_pct[i,j]:.0f}%)' for j in range(len(LABEL_ORDER))]\n",
    "     for i in range(len(LABEL_ORDER))]\n",
    ")\n",
    "\n",
    "sns.heatmap(\n",
    "    cm_pct, annot=annot, fmt='',\n",
    "    xticklabels=LABEL_ORDER, yticklabels=LABEL_ORDER,\n",
    "    cmap='Blues', ax=ax,\n",
    "    linewidths=0.5, linecolor='#F2F2F7',\n",
    "    cbar_kws={'shrink': 0.8}\n",
    ")\n",
    "ax.set_title(f'Confusion Matrix ‚Äî LLM\\nAccuracy: {acc:.4f}', fontweight='bold', fontsize=12)\n",
    "ax.set_xlabel('Prediksi', fontsize=11)\n",
    "ax.set_ylabel('Aktual', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('llm_confusion_matrix.png', dpi=150, bbox_inches='tight', facecolor='#F2F2F7')\n",
    "plt.show()\n",
    "\n",
    "print('\\nüìù Interpretasi Confusion Matrix:')\n",
    "for i, label in enumerate(LABEL_ORDER):\n",
    "    row_sum = cm[i].sum()\n",
    "    correct = cm[i, i]\n",
    "    if row_sum > 0:\n",
    "        print(f'   {label:10s}: {correct}/{row_sum} benar ({correct/row_sum*100:.1f}% recall)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùå Cell 9 ‚Äî Analisis Kesalahan Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salah = df_hasil[~df_hasil['benar']].copy()\n",
    "\n",
    "print(f'‚úÖ Prediksi benar : {df_hasil[\"benar\"].sum()} / {len(df_hasil)}')\n",
    "print(f'‚ùå Prediksi salah : {(~df_hasil[\"benar\"]).sum()} / {len(df_hasil)}')\n",
    "\n",
    "if len(df_salah) > 0:\n",
    "    print(f'\\n‚îÄ‚îÄ‚îÄ Pola Kesalahan ‚îÄ‚îÄ‚îÄ')\n",
    "    pola = df_salah.groupby(['label_aktual', 'pred_llm']).size().reset_index(name='count')\n",
    "    pola = pola.sort_values('count', ascending=False)\n",
    "    for _, row in pola.iterrows():\n",
    "        print(f'   {row[\"label_aktual\"]:10s} ‚Üí diprediksi {row[\"pred_llm\"]:10s}: {row[\"count\"]} kasus')\n",
    "\n",
    "    print(f'\\n‚îÄ‚îÄ‚îÄ 10 Contoh Kesalahan Prediksi ‚îÄ‚îÄ‚îÄ')\n",
    "    for _, row in df_salah.head(10).iterrows():\n",
    "        teks_preview = row['teks'][:65] + '...' if len(row['teks']) > 65 else row['teks']\n",
    "        print(f'   Aktual: {row[\"label_aktual\"]:10s} | Prediksi: {row[\"pred_llm\"]:10s}')\n",
    "        print(f'   Teks  : \"{teks_preview}\"')\n",
    "        print()\n",
    "\n",
    "# Export hasil prediksi\n",
    "df_hasil.to_csv('hasil_prediksi_llm.csv', index=False, encoding='utf-8-sig')\n",
    "print('üíæ Tersimpan: hasil_prediksi_llm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Cell 10 ‚Äî Prediksi Teks Baru Interaktif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_sentimen(teks_input):\n",
    "    \"\"\"\n",
    "    Prediksi sentimen teks baru dengan tampilan detail.\n",
    "    Untuk LLM, kita juga meminta penjelasan singkat.\n",
    "    \"\"\"\n",
    "    if not teks_input or not teks_input.strip():\n",
    "        print('‚ö†Ô∏è  Teks kosong!')\n",
    "        return\n",
    "\n",
    "    # Prediksi label\n",
    "    label = predict_llm(teks_input)\n",
    "\n",
    "    # Minta penjelasan singkat\n",
    "    messages_explain = [\n",
    "        {\"role\": \"system\", \"content\": \"Kamu adalah analis sentimen. Berikan penjelasan singkat (1-2 kalimat) mengapa teks berikut termasuk sentimen yang disebutkan.\"},\n",
    "        {\"role\": \"user\", \"content\": f'Teks: \"{teks_input}\"\\nSentimen: {label}\\nJelaskan singkat:'}\n",
    "    ]\n",
    "    try:\n",
    "        resp_explain = client.chat.completions.create(\n",
    "            model=MODEL_LLM,\n",
    "            messages=messages_explain,\n",
    "            max_tokens=150,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        alasan = resp_explain.choices[0].message.content.strip()\n",
    "    except:\n",
    "        alasan = '(penjelasan tidak tersedia)'\n",
    "\n",
    "    icon = {'Negatif': 'üî¥', 'Netral': '‚ö™', 'Positif': 'üü¢'}.get(label, '‚ö´')\n",
    "\n",
    "    print(f'  Input     : \"{teks_input[:70]}\"')\n",
    "    print(f'  Prediksi  : {icon} {label}')\n",
    "    print(f'  Alasan    : {alasan}')\n",
    "    print()\n",
    "\n",
    "    return {'label': label, 'alasan': alasan}\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Uji coba prediksi ‚îÄ‚îÄ‚îÄ\n",
    "teks_uji = [\n",
    "    'Alhamdulillah jalan depan rumah akhirnya diperbaiki, terima kasih pak bupati!',\n",
    "    'Jalan masih rusak parah, kapan diperbaiki? Sudah bertahun-tahun begini.',\n",
    "    'Cukup bagus kepemimpinan bapa bupati, semoga terus maju.',\n",
    "    'Ga ngaruh apa2. Sama aja bohong. Hahaha.',\n",
    "    'Hmm biasa aja sih, gak ada yang spesial.',\n",
    "    'Pengangguran masih tinggi, lapangan kerja kurang, galian pasir masih beroperasi.',\n",
    "]\n",
    "\n",
    "print('=' * 60)\n",
    "print('üß™ PREDIKSI TEKS BARU')\n",
    "print('=' * 60)\n",
    "for teks in teks_uji:\n",
    "    analisis_sentimen(teks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Cell 11 ‚Äî Simpan Hasil & Laporan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Simpan metadata & hasil evaluasi\n",
    "model_info = {\n",
    "    'nama_model':    MODEL_LLM,\n",
    "    'provider':      'SumoPod AI (OpenAI-compatible)',\n",
    "    'metode':        'Few-shot prompting',\n",
    "    'few_shot_n':    FEW_SHOT_N,\n",
    "    'n_eval':        len(X_eval),\n",
    "    'hasil_evaluasi': {\n",
    "        'accuracy':   round(float(acc), 4),\n",
    "        'macro_f1':   round(float(macro_f1), 4),\n",
    "        'per_kelas': {\n",
    "            label: {\n",
    "                'precision': round(float(precision_score(y_eval, y_pred_llm, labels=[label], average='macro', zero_division=0)), 4),\n",
    "                'recall':    round(float(recall_score(y_eval, y_pred_llm, labels=[label], average='macro', zero_division=0)), 4),\n",
    "                'f1':        round(float(f1_score(y_eval, y_pred_llm, labels=[label], average='macro', zero_division=0)), 4),\n",
    "                'support':   int(np.sum(y_eval == label)),\n",
    "            } for label in LABEL_ORDER\n",
    "        },\n",
    "    },\n",
    "    'label_map':     {'Negatif': 0, 'Netral': 1, 'Positif': 2},\n",
    "    'cara_pakai': [\n",
    "        \"from openai import OpenAI\",\n",
    "        \"client = OpenAI(api_key='sk-...', base_url='https://ai.sumopod.com/v1')\",\n",
    "        \"label = predict_llm(teks)  # gunakan fungsi predict_llm()\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('llm_model_info.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(model_info, f, ensure_ascii=False, indent=2)\n",
    "print('‚úÖ Tersimpan: llm_model_info.json')\n",
    "\n",
    "# ZIP semua output\n",
    "output_files = [\n",
    "    'hasil_prediksi_llm.csv', 'llm_model_info.json',\n",
    "    'llm_distribusi_kelas.png', 'llm_metrik_kelas.png', 'llm_confusion_matrix.png',\n",
    "]\n",
    "\n",
    "with zipfile.ZipFile('SENTALIS_LLM_output.zip', 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "    for fname in output_files:\n",
    "        if os.path.exists(fname):\n",
    "            zf.write(fname)\n",
    "            print(f'  + {fname}')\n",
    "\n",
    "print(f'\\nüì¶ ZIP: SENTALIS_LLM_output.zip ({os.path.getsize(\"SENTALIS_LLM_output.zip\")/1024:.1f} KB)')\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('SENTALIS_LLM_output.zip')\n",
    "    print('‚¨áÔ∏è  Download dimulai...')\n",
    "except ImportError:\n",
    "    print('üìÇ File tersimpan di direktori saat ini.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Ringkasan & Catatan Penting\n",
    "\n",
    "### Keunggulan LLM vs TF-IDF + Naive Bayes\n",
    "\n",
    "| Aspek | TF-IDF + NB | LLM (seed-2-0-mini) |\n",
    "|---|---|---|\n",
    "| **Training data** | Diperlukan | ‚ùå Tidak perlu (zero/few-shot) |\n",
    "| **Pemahaman konteks** | Terbatas | ‚úÖ Lebih dalam |\n",
    "| **Bahasa Sunda/slang** | Bergantung kosakata | ‚úÖ Lebih robust |\n",
    "| **Imbalanced data** | Bermasalah | ‚úÖ Tidak terpengaruh |\n",
    "| **Kecepatan** | ‚úÖ Sangat cepat | ‚ùå Lambat (API call per data) |\n",
    "| **Biaya** | ‚úÖ Gratis | Tergantung API pricing |\n",
    "| **Interpretasi** | Bisa lihat fitur | ‚ùå Black box |\n",
    "\n",
    "### Tips Meningkatkan Akurasi LLM\n",
    "\n",
    "Untuk mendapatkan hasil yang lebih baik, Anda dapat mencoba:\n",
    "- Menambah jumlah few-shot examples (dari 2 menjadi 5 per kelas)\n",
    "- Memperkaya system prompt dengan penjelasan konteks yang lebih detail\n",
    "- Menggunakan model yang lebih besar (misal `seed-2-0` non-free)\n",
    "- Menerapkan chain-of-thought: minta LLM jelaskan dulu, baru beri label\n",
    "\n",
    "### Cara Pakai Fungsi Prediksi\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-vAAu3GrFUtzmkbPe5tAHSg\",\n",
    "    base_url=\"https://ai.sumopod.com/v1\"\n",
    ")\n",
    "\n",
    "teks = \"Jalan masih rusak dan gelap!\"\n",
    "label = predict_llm(teks)  # 'Negatif'\n",
    "```\n",
    "\n",
    "---\n",
    "*SENTALIS ‚Äî LLM Edition*  \n",
    "*Few-shot Sentiment Analysis menggunakan seed-2-0-mini via SumoPod AI*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "name": "SENTALIS_LLM.ipynb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
